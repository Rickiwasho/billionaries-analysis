{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2: ¿Es posible explicar la cantidad de billonarios en base al desarrollo país?  <a class=\"tocSkip\"></a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 2006 *Daniel Treisman* publicó un artículo titulado [*Russia Billionaries*](https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.p20161068) en el cual conectó la cantidad de billonarios de un país con ciertos atributos económicos de los mismos. \n",
    "\n",
    "Su conclusión principal fue que ***Rusia tiene una cantidad de billonarios mayor que la que predicen los indicadores económicos***\n",
    "\n",
    "En esta tarea ustedes analizarán datos macroeconómicos para comprobar o refutar los hallazgos de *D. Treisman*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales \n",
    "\n",
    "1. Forme un grupo de **máximo tres estudiantes**\n",
    "1. Versione su trabajo usando un **repositorio privado de github**. Agregue a sus compañeros y a su profesor (usuario github: phuijse) en la pestaña *Settings/Manage access*. No se aceptarán consultas de programación si no se cumple este requisito\n",
    "1. Su tarea se evaluará en base al último commit antes de la fecha de entrega: **14:10 del Martes 15 de Junio de 2021**. La nota se calcula como (\"pt totales\" + 1)\n",
    "1. [Sean leales y honestos](https://www.acm.org/about-acm/code-of-ethics-in-spanish), no copie ni comparta resultados con otros grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Para esta tarea se les provee de un conjunto de datos `billonarios.csv` indexado por país con los siguientes atributos\n",
    "\n",
    "- `nbillonarios`: La cantidad de billonarios del pais\n",
    "- `logpibpc`: El logaritmo del Producto Interno Bruto (PIB) per capita del pais\n",
    "- `logpob`: El logaritmo de la población del pais\n",
    "- `gatt`: La cantidad de años que el pais está adherido al *General Agreement on Tariffs and Trade* (GATT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n",
    "import scipy\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importamos dataset\n",
    "df = pd.read_csv(\"billonarios.csv\")\n",
    "\n",
    "# Nº de billonarios\n",
    "y = df.iloc[:,1].to_numpy().astype('float128')\n",
    "\n",
    "# Resto de variables\n",
    "x = df.iloc[:,2:].to_numpy().astype('float128')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo (1.0pt)\n",
    "\n",
    "El objetivo principal de esta tarea es entrenar un modelo de regresión que prediga la cantidad de billonarios en función de los demás atributos\n",
    "\n",
    "> El número de billonarios es una variable entera y no-negativa. \n",
    "\n",
    "Un modelo apropiado en este caso es la [regresión de Poisson](https://en.wikipedia.org/wiki/Poisson_distribution), donde definimos la probabilidad condicional para un pais $i$ como  \n",
    "\n",
    "$$\n",
    "p(y_i | x_i ) = \\frac{\\lambda_i^{y_i}}{y_i!} \\exp \\left ({-\\lambda_i} \\right)\n",
    "$$\n",
    "\n",
    "con intensidad\n",
    "\n",
    "$$\n",
    "\\lambda_i = \\exp \\left (\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij} \\right)\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "- $\\theta$ es el vector de parámetros que deseamos ajustar \n",
    "- $y_i$ y $x_i$ son la cantidad de billonarios y el vector de atributos del país $i$, respectivamente\n",
    "\n",
    "En base a este modelo se pide que ajusten $\\theta$ mediante la maximización de la verosimilitud. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg}\\max_\\theta \\log \\mathcal{L} (\\theta) \\nonumber \\\\ \n",
    "&= \\text{arg}\\max_\\theta \\log \\prod_{i=1}^N  p(y_i | x_i) \\nonumber \\\\\n",
    "&= \\text{arg}\\max_\\theta \\sum_{i=1}^N \\log p(y_i | x_i) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "En particular:\n",
    "\n",
    "**1. Estudie y describa la distribución de Poisson en detalle. Muestre como varía la distribución en función de su parámetro $\\lambda$, ¿Qué ocurre cuando $\\lambda$ es pequeño? ¿Y cuando es grande?**\n",
    "\n",
    "La distribución de Poisson es una distribución de tipo discreta que permite modelar la probabilidad de que k fenómenos ocurran en un periodo fijo de tiempo (conociendo la tasa media (λ) de ocurrencia de estos). Además se supone que los tiempos entre ocurrencias son independientes entre sí y distribuidos exponencialmente. Esto significa que por ejemplo, si se conoce la tasa media de llegada de micros a un paradero (1 cada 15 minutos) y han transcurrido 5 minutos desde la última llegada, la probabilidad con la que se debe esperar 15 minutos para que llegue una nueva micro sigue siendo la misma que si hubieran transcurrido 0 minutos, o sea, los tiempos entre llegadas son independientes entre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = np.arange(0,26,1)\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "@widgets.interact(λ=(0, 25, 0.5))\n",
    "def poissonMass(λ):\n",
    "    y = poisson.pmf(k,λ)\n",
    "    ax.cla()\n",
    "    ax.set_title(\"Función de masa de probabilidad de Poisson con λ = \" + str(λ))\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel(\"P(x = k)\")\n",
    "    ax.set_xlabel(\"Número de ocurrencias (k)\")\n",
    "    ax.plot(k,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "h = ax.hist(y,50,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Media y:\",np.mean(df.iloc[:,1]),\"Varianza y:\",np.var(df.iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianza mucho mayor que la media, por lo tanto suponemos que habrá sobre dispersión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la distribución se asemeja a una distribución normal, cuya media o centro parece ser igual al parámetro λ. También podemos observar que a medida que λ aumenta, también lo hace la varianza.\n",
    "    \n",
    "**2. Reemplace las expresiones y obtenga una expresión analítica para el logaritmo de la verosimilitud: $\\log \\mathcal{L}(\\theta)$. Muestre la ecuación obtenida. HINT: Puede ignorar los términos que no dependan de $\\theta$. Luego obtenga una expresión analítica para la primera derivada del logaritmo de la verosimilitud. Muestra la ecuación obtenida**\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\mathcal{L}(\\theta) &= \\sum_{i=1}^N \\log p(y_i | x_i) \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "&= \\sum_{i=1}^N \\log\\left(\\frac{\\lambda_i^{y_i}}{y_i!} e^{-\\lambda_i}\\right) \\nonumber \\\\\n",
    "\\text{Usamos propiedad logarítmica:} \\nonumber \\\\ \n",
    "\\log(a \\cdot b) = \\log(a) + \\log(b) \\nonumber \\\\ \n",
    "\\nonumber \\\\ \n",
    "&= \\sum_{i=1}^N \\left( \\log\\left(\\frac{\\lambda_i^{y_i}}{y_i!} \\right) + \\log\\left(e^{-\\lambda_i}\\right) \\right) \\nonumber \\\\\n",
    "&= \\sum_{i=1}^N \\left( \\log\\left(\\frac{\\lambda_i^{y_i}}{y_i!} \\right) - \\lambda_i \\right)  \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "\\text{Usamos propiedad logarítmica:} \\nonumber \\\\ \n",
    "\\log\\left(\\frac{a}{b}\\right) = \\log(a) - \\log(b) \\nonumber \\\\ \n",
    "\\nonumber \\\\ \n",
    "&= \\sum_{i=1}^N \\left( \\log\\left(\\lambda_i^{y_i}\\right) - \\log(y_i!) - \\lambda_i \\right)  \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "\\text{Reemplazamos } \\lambda_i \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "&= \\sum_{i=1}^N \\left( \\log \\left(\\left(e^{\\left(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}\\right)}\\right)^{y_i}\\right) - \\log(y_i!) - e^{\\left(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}\\right)} \\right) \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "\\text{Usamos propiedad exponencial:} \\nonumber \\\\ \n",
    "(e^{a})^{b} = e^{a \\cdot b} \\nonumber \\\\ \n",
    "\\nonumber \\\\ \n",
    "&= \\sum_{i=1}^N \\left( \\log \\left(e^{\\left(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}\\right)y_i}\\right) - \\log(y_i!) - e^{\\left(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}\\right)} \\right) \\nonumber \\\\\n",
    "&= \\sum_{i=1}^N \\left( (\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}) y_i - \\log(y_i!) - e^{(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij})} \\right) \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "\\text{Por último, podemos eliminar } \\log(y_i!) \\text{ ya que no depende de }\\theta \\nonumber \\\\\n",
    "\\nonumber \\\\ \n",
    "&= \\sum_{i=1}^N \\left( (\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}) y_i - e^{(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij})} \\right) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivada\n",
    "La derivada respecto a  $ \\theta_j$ con $\\text{j = 0}$ es:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{d\\theta_0}\\log \\mathcal{L}(\\theta) &= \\sum_{i=1}^N\\left( y_i - e^{(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij})} \\right) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Y para $\\text{j > 0}$ es:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{d\\theta_j}\\log \\mathcal{L}(\\theta) &= \\sum_{i=1}^N\\left( x_{ij} y_i - x_{ij}e^{(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij})} \\right) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación (1.5pt)\n",
    "\n",
    "**1. Implemente el logaritmo de la verosimilitud y su derivada usando `numpy`. Utilice operaciones vectoriales (prohibido usar `for` para iterar en los países)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de costo\n",
    "def loglikelihood(theta,*args):\n",
    "    x = args[0]\n",
    "    y = args[1]\n",
    "    \n",
    "    p = theta[0] + np.sum(theta[1:]*x,axis=1)\n",
    "    \n",
    "    # Cambiamos signo para que se convierta en minimización\n",
    "    return -np.sum(p*y - np.exp(p))\n",
    "\n",
    "\n",
    "# Gradiente\n",
    "def grad_loglikelihood(theta,*args):\n",
    "    x = args[0]\n",
    "    y = args[1]\n",
    "    \n",
    "    res = np.array([0,0,0,0]).astype('float128')\n",
    "    \n",
    "    # j = 0\n",
    "    p = theta[0] + np.sum(theta[1:]*x,axis=1)\n",
    "    res[0] = np.sum(y-np.exp(p))\n",
    "    \n",
    "    # j > 0\n",
    "    res[1] = np.sum(x[:,0]*(y - np.exp(p)))\n",
    "    res[2] = np.sum(x[:,1]*(y - np.exp(p)))\n",
    "    res[3] = np.sum(x[:,2]*(y - np.exp(p)))\n",
    "    \n",
    "    return -res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Implemente una rutina que encuentre el vector de parámetros óptimo en base a `scipy.optimize.minimize`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTheta(x,y,method='BFGS',thetaInit = np.array([0.0,0,0,0]),tol=1e-5):\n",
    "    res = scipy.optimize.minimize(fun=loglikelihood,\n",
    "                                    x0=thetaInit,\n",
    "                                    method=method,\n",
    "                                    jac=grad_loglikelihood,\n",
    "                                    options={'maxiter':10e3,'maxfev':10e3},\n",
    "                                    args=(x,y),\n",
    "                                    tol=tol)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Implemente una rutina que calcule el pseudo coeficiente de correlación\n",
    "$$\n",
    "R^2 = \\frac{\\log \\mathcal{L} (\\hat \\theta_0) - \\log \\mathcal{L} (\\hat \\theta) }{\\log \\mathcal{L} (\\hat \\theta_0)} \\in [0, 1]\n",
    "$$\n",
    "donde $\\log \\mathcal{L} (\\hat \\theta)$ es el logaritmo de la verosimilitud de su mejor modelo y $\\log \\mathcal{L} (\\hat \\theta_0)$ es el logaritmo de la verosimilitud de un modelo que tiene sólo el parámetro $\\theta_0$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma de logaritmos de factoriales de un vector\n",
    "def logFactorial(vec):\n",
    "    suma = 0.0\n",
    "    for y in vec:\n",
    "        if y != 0:\n",
    "            suma += np.sum(np.log(np.arange(1,y+1,1)))\n",
    "    return suma\n",
    "\n",
    "# Pseudo coeficiente de correlación de McFadden\n",
    "def corrCoef(x,y,theta):\n",
    "    \n",
    "    # log(y!)\n",
    "    yFact = logFactorial(y)\n",
    "    \n",
    "    # Mejor modelo solo theta\n",
    "    theta0 = np.log(np.mean(y)+1e-100)\n",
    "    \n",
    "    logVer = -loglikelihood(theta,x,y)\n",
    "    logVer0 = -loglikelihood(np.array([theta0,0,0,0]),x,y)\n",
    "    return  (logVer0 - logVer)/(logVer0-yFact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Implemente una rutina de bootstrap resampling para encontrar la distribución y los intervalos de confianza empíricos para $\\theta$ y el pseudo coeficiente de correlación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson supone ocurrencias independienes por lo tanto utilizamos meustreo con reemplazo\n",
    "def bootstrap(x,y,B,N,method):\n",
    "    # B = número de muestras\n",
    "    # N = tamaño de cada muestra\n",
    "    \n",
    "    # Almacena estadísticos de los datos ( muestra completa )\n",
    "    resDatos = np.zeros(5,dtype='float128')\n",
    "    \n",
    "    # Calcula theta con todos los datos\n",
    "    resDatos[:4] = findTheta(x,y,method,tol=1e-6).x\n",
    "\n",
    "    # Y el coeficiente de correlación\n",
    "    resDatos[4] = corrCoef(x,y,resDatos[:4])\n",
    "\n",
    "    # Almacena coeficientesB\n",
    "    resB = np.zeros((B,5),dtype='float128')\n",
    "\n",
    "    for i in range(B):\n",
    "\n",
    "        # Genera muestra aleatoria de N elementos\n",
    "        indexs = np.random.choice(N, size=N, replace=True)    \n",
    "        yB = y[indexs]\n",
    "        xB = x[indexs,:]\n",
    "\n",
    "        # Calcula coeficientes en cada muestra B\n",
    "        success = False\n",
    "        while success == False:\n",
    "            thetaInit = np.array([0.0,0,0,0]) + 1.0 * np.random.randn(4)\n",
    "\n",
    "            res = scipy.optimize.minimize(fun=loglikelihood,\n",
    "                                        x0=thetaInit,\n",
    "                                        method=method,\n",
    "                                        jac=grad_loglikelihood,\n",
    "                                        args=(xB,yB),\n",
    "                                        tol=1e-5)\n",
    "            success = res.success\n",
    "                \n",
    "        \n",
    "        # Guardamos thetaB\n",
    "        resB[i,:4] = res.x\n",
    "\n",
    "        # Guardamos coefCorrB\n",
    "        resB[i,4] = corrCoef(xB,yB,res.x)\n",
    "\n",
    "    intervalos = np.zeros((5,2))\n",
    "    for i in range(5):\n",
    "        intervalos[i,:] = np.quantile(a = resB[:,i], q = [0.025, 0.975])\n",
    "    \n",
    "    return resB,resDatos,intervalos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados (3pt)\n",
    "\n",
    "1. Compare los métodos `CG`, `BFGS`, `Nelder-mead` y `Powell` en términos del vector de parámetros obtenido, la log verosimilitud alcanzada, el pseudo coeficiente de correlación alcanzado, el número de iteraciones necesarias para converger y el tiempo total para converger. Seleccione uno de los métodos para contestar los siguientes puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tol = 1e-9\n",
    "methods = ['CG','BFGS','Nelder-mead','Powell']\n",
    "results = pd.DataFrame(columns=['Método','Iters','Log Verosimilitud','Coef Correlación','θ0','θ1','θ2','θ3'])\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    %timeit -r 5 -n 5 findTheta(x,y,methods[i],tol=tol)\n",
    "    res = findTheta(x,y,methods[i],tol=tol)\n",
    "    results.loc[i] = [methods[i],res.nit,res.fun,corrCoef(x,y,res.x),res.x[0],res.x[1],res.x[2],res.x[3]]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que todos los métodos convergen al mismo valor (con ínfimas diferencias en los valores de theta). La principal diferencia radica en el número de iteraciones necesarias para converger y el tiempo empleado.\n",
    "El algoritmo que registra un mejor rendimiento es **BFGS** con un tiempo promedio de 6.24 milisegundos y 17 iteraciones, el algoritmo **Powell** requiere menos iteraciones pero tarda casi un órden de magnitud más en converger, probablemente porque no hace uso de la función gradiente implementada previamente. Dicho eso, optamos por el método **BFGS**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Muestre las distribuciones empíricas de los parámetros y del pseudo coeficiente de correlación. ¿Cuáles parámetros tienen $\\theta$ significativamente distinto de cero? ¿Cuál es el intervalo de confianza al 95% del $R^2$? En base a esto ¿Qué puede decir sobre su modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resB,resDatos,intervalos = bootstrap(x,y,B=10000,N=len(y),method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resB_,resDatos_,intervalos_ = resB,resDatos,intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(9,6),tight_layout=True)\n",
    "g = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):   \n",
    "        ax[i,j].hist(resB[:,g], bins=300, density=True, color='#3182bd', alpha=0.5)\n",
    "        ax[i,j].axvline(x=resDatos[g], color='firebrick', label='Theta'+str(g)+' Modelo')\n",
    "        ax[i,j].axvline(x=intervalos[g][0], color='black', linestyle='--', label='IC 95%')\n",
    "        ax[i,j].axvline(x=intervalos[g][1], color='black', linestyle='--')\n",
    "        ax[i,j].hlines(y=0.001, xmin=intervalos[g][0], xmax=intervalos[g][1], color='black')\n",
    "        ax[i,j].set_title('Distribución Empírica Theta'+str(g))\n",
    "        ax[i,j].set_xlabel('theta')\n",
    "        ax[i,j].set_ylabel('densidad')\n",
    "        ax[i,j].legend();\n",
    "        g+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ambas modas del coeficiente theta0 (media flotante) se alejan bastante de 0, a diferencia del resto, sobre todo theta3 que corresponde al peso del parámetro GATT, por lo tanto podemos inferir que la variable GATT no aporta demasiada información al modelo, o dicho de otra forma, no posee una correlación fuerte con la cantidad de billonarios de un país, a diferencia del PIB y la cantidad de población ( con pesos theta1 y theta2 respectativamente) que si poseen una clara correlación positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCC\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(9,6),tight_layout=True)\n",
    "ax.hist(resB[:,4], bins=300, density=True, color='#3182bd', alpha=0.5)\n",
    "ax.axvline(x=resDatos[4], color='firebrick', label='PCC Modelo')\n",
    "ax.axvline(x=intervalos[4][0], color='black', linestyle='--', label='IC 95%')\n",
    "ax.axvline(x=intervalos[4][1], color='black', linestyle='--')\n",
    "ax.hlines(y=0.001, xmin=intervalos[4][0], xmax=intervalos[4][1], color='black')\n",
    "ax.set_title('Distribución Empírica Pseudo CC')\n",
    "ax.set_xlabel('PCC')\n",
    "ax.set_ylabel('densidad')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El intervalo de confianza al 95% de $R^2$ es: $[0.67147728, 0.94130836]$\n",
    "\n",
    "Al existir dos modas, creemos que hay dos grupos de países a los cuales el modelo podría ajustarse correctamente por separado. Probablemente existen variables adicionales que hubiesen explicado esta separación en un modelo con más dimensiones, pero esas variables no se tomaron en cuenta en este trabajo. Dado que el $R^2$ obtenido con todos los datos se aproxima más a la segunda moda, podemos inferir que nuestro modelo será bueno para predecir países similares a ese grupo pero el grado de incerteza aumentará en otro caso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prediga la cantidad de billonarios de cada país usando su modelo. Gráfique el error entre la cantidad de billonarios predicha y la cantidad de billonarios real. El gráfico debe mostrar los paises ordenados de mayor a menor **error absoluto**.  Analice ¿Cuáles son los 5 países con mayor error en la predicción? ¿Cuáles países tienen un exceso de billonarios? ¿Cúales paises tienen menos billonarios de lo esperado? ¿Qué puede decir sobre Rusia?\n",
    "\n",
    "Dado que el modelo genera una distribución de Poisson específica para cada input x, y sabemos que su media es equivalente a su parámetro $\\lambda$, podemos utilizar: \n",
    "\n",
    "$$\n",
    "\\lambda = \\exp \\left (\\theta_0 + \\sum_{j=1}^M \\theta_j x_{j} \\right)\n",
    "$$\n",
    "\n",
    "Para predecir la cantidad de billonarios, pero con el resultado truncado para obtener valores discretos.\n",
    "\n",
    "$$\n",
    "y = floor \\left( \\lambda \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,theta):\n",
    "    return np.floor(np.exp(theta[0]+np.sum(x*theta[1:],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yReal = df.iloc[:,0:4]\n",
    "yPred = model(x,resDatos[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error absoluto\n",
    "yErr = yReal.copy()\n",
    "yErr.columns = ['pais','real','pred','err']\n",
    "yErr.iloc[:,2] = yPred\n",
    "yErr.iloc[:,3] = np.abs(yErr.iloc[:,1] - yPred[:])\n",
    "yErr = yErr.sort_values(by=['err'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(9,6),tight_layout=True)\n",
    "ax.set_title('Error Absoluto de Predicciones')\n",
    "ax.set_ylabel('Billonarios')\n",
    "plt.plot(yErr.iloc[:,0], yErr.iloc[:,3], c='red',alpha=0.5,label='Error')\n",
    "plt.xticks(rotation=90,fontsize=6)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(9,6),tight_layout=True)\n",
    "ax.set_title('Predicción Billonarios')\n",
    "ax.set_ylabel('Billonarios')\n",
    "plt.plot(yErr.iloc[:,0], yErr.iloc[:,2], c='red',alpha=0.5,label='Predicción')\n",
    "plt.plot(yErr.iloc[:,0], yErr.iloc[:,1],c='blue',alpha=0.5,label='Valor Real')\n",
    "plt.xticks(rotation=90,fontsize=6)\n",
    "#plt.yscale('log')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los cinco países con mayor error absoluto son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yErr.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe tener en cuenta que estos países tienen grandes diferencias en los tamaños de sus poblaciones. Creemos que a mayor tamaño de población, el error absoluto tenderá naturalmente a ser mayor, por lo que podría ser útil ver los errores relativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errores relativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones (0.5pt)\n",
    "\n",
    "Resuma sus principales hallazgos y comenté sobre las desafios encontrados al desarrollar esta tarea "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
